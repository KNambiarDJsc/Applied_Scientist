{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-08T07:58:14.626094Z","iopub.execute_input":"2025-09-08T07:58:14.626287Z","iopub.status.idle":"2025-09-08T07:58:16.717831Z","shell.execute_reply.started":"2025-09-08T07:58:14.626268Z","shell.execute_reply":"2025-09-08T07:58:16.716828Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"In this notebook, we embark on a journey to understand the design philosophy of LLaMA 3.2 while implementing and testing its cutting-edge features. This will deepen our expertise in building and utilizing state-of-the-art large language models.","metadata":{}},{"cell_type":"code","source":"import torch \nimport torch.nn as nn \nimport torch.nn.functional as F\nimport tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T08:06:21.381841Z","iopub.execute_input":"2025-09-08T08:06:21.382090Z","iopub.status.idle":"2025-09-08T08:06:25.851280Z","shell.execute_reply.started":"2025-09-08T08:06:21.382068Z","shell.execute_reply":"2025-09-08T08:06:25.850488Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class Llama3(nn.Module):\n    def __init__(self,config):\n        super().__init__()\n        self.config = config\n        self.token_emedding = nn.Embedding(\n            config['vocab_size'], config['emb_dim'], dtype=config['dtype']\n        )\n                # Stack of transformer blocks, forming the core of the model\n        self.tras_blocks = nn.Sequential(\n            *[TransformerBlock(config) for _ in range(config['n_layers'])]\n        )\n        # Final RMSNorm layer to normalize outputs of the transformer stack\n        self.final_norm = nn.RMSNorm(config['emb_dim'])\n        # Linear layer to project the hidden states back to the vocabulary size\n        self.output = nn.Linear(\n            config['emb_dim'], config['vocab_size'], bias=False, dtype=config['dtype']\n        )\n\n    def forward(self, x):\n        # Token embedding: Convert input token indices to dense embeddings\n        tok_emb = self.token_emedding(x)\n        x = tok_emb\n        # Pass through the stack of transformer blocks\n        x = self.tras_blocks(tok_emb)\n        # Normalize the output of the transformer stack\n        x = self.final_norm(x)\n        # Project the normalized output to the vocabulary space and return logits\n        logits = self.output(x.to(torch.bfloat16))\n        return logits\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T08:06:25.852686Z","iopub.execute_input":"2025-09-08T08:06:25.853052Z","iopub.status.idle":"2025-09-08T08:06:25.859319Z","shell.execute_reply.started":"2025-09-08T08:06:25.853026Z","shell.execute_reply":"2025-09-08T08:06:25.858443Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class RMSNorm(nn.Module):\n    def __init__(self, config, eps=1e-5):\n        super().__init__()\n        # Store the configuration and epsilon value for numerical stability\n        self.config = config\n        self.eps = eps\n        \n        # Initialize the scale parameter (gamma), which will be learned during training\n        # It has the same shape as the embedding dimension (config['emb_dim'])\n        self.scale = nn.Parameter(torch.ones(config['emb_dim']))  \n\n    def forward(self, x):\n        # Compute the mean squared value of the input tensor across the last dimension\n        # This is used to calculate the RMS (Root Mean Square) of each element in the input\n        mean = x.pow(2).mean(dim=-1, keepdim=True)  # mean(x^2) along the last dimension\n        \n        # Normalize the input by dividing each element by the RMS of that element\n        # torch.rsqrt computes the inverse square root (1/sqrt(x))\n        x_norm = x * torch.rsqrt(mean + self.eps)  # Normalize using RMS\n        \n        # Apply the learnable scale parameter (gamma) to the normalized tensor\n        # This scale parameter allows the model to learn the optimal scaling factor\n        output = (self.scale * x_norm).to(dtype=x.dtype)  # Ensure the output has the same dtype as the input\n        \n        # Return the scaled and normalized tensor\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T08:06:25.859886Z","iopub.execute_input":"2025-09-08T08:06:25.860138Z","iopub.status.idle":"2025-09-08T08:06:25.883220Z","shell.execute_reply.started":"2025-09-08T08:06:25.860118Z","shell.execute_reply":"2025-09-08T08:06:25.882316Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define a sample configuration\nconfig = {'emb_dim': 2048}\n\n# Create a random input tensor\nx = torch.randn(16, 32, config['emb_dim'])\n\n# Create an instance of our custom RMSNorm\ncustom_rmsnorm = RMSNorm(config)\ncustom_output = custom_rmsnorm(x)\n\n# Try PyTorch's RMSNorm implementation (if available)\ntry:\n    from torch.nn import RMSNorm as TorchRMSNorm\n    \n    # Create an instance of PyTorch's RMSNorm\n    torch_rmsnorm = TorchRMSNorm(config['emb_dim'], eps=1e-5)\n    torch_output = torch_rmsnorm(x)\n    \n    # Compare the outputs (check if they are the same)\n    outputs_are_equal = torch.allclose(custom_output, torch_output)\n    print(f\"Are the outputs equal? {outputs_are_equal}\")\nexcept ImportError:\n    print(\"PyTorch RMSNorm is not available. Custom RMSNorm implementation is being used.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T08:06:49.782022Z","iopub.execute_input":"2025-09-08T08:06:49.782933Z","iopub.status.idle":"2025-09-08T08:06:49.920646Z","shell.execute_reply.started":"2025-09-08T08:06:49.782876Z","shell.execute_reply":"2025-09-08T08:06:49.919798Z"}},"outputs":[{"name":"stdout","text":"Are the outputs equal? True\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        # Initialize the multi-head attention layer\n        self.att = GroupedQueryAttention(\n            d_in=config[\"emb_dim\"],\n            d_out=config[\"emb_dim\"],\n            context_length=config[\"context_length\"],\n            num_heads=config[\"n_heads\"],\n            num_kv_groups=config[\"n_kv_groups\"],\n            rope_base=config[\"rope_base\"],\n            rope_config=config[\"rope_freq\"],\n            dtype=config[\"dtype\"]\n        )\n        # Initialize the feedforward layer\n        self.ff = FeedForward(config)  # Assuming FeedForward is defined elsewhere\n        # Initialize layer normalization layers\n        self.norm1 = nn.RMSNorm(config['emb_dim'])  # First normalization layer\n        self.norm2 = nn.RMSNorm(config['emb_dim'])  # Second normalization layer\n\n    def forward(self, x):\n        # Pass the input through the multi-head attention layer\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x.to(torch.bfloat16))\n        x = x + shortcut  # Residual connection\n        \n        # Pass the output through the feedforward layer\n        shortcut = x  # Update shortcut after attention\n        x = self.norm2(x)\n        x = self.ff(x.to(torch.bfloat16))\n        x = x + shortcut  # Residual connection\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:03:32.914927Z","iopub.execute_input":"2025-09-08T09:03:32.915502Z","iopub.status.idle":"2025-09-08T09:03:32.921444Z","shell.execute_reply.started":"2025-09-08T09:03:32.915480Z","shell.execute_reply":"2025-09-08T09:03:32.920602Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"1- FeedForward Layer with SiLU Activation\nThe FeedForward layer in a transformer block consists of two main components:\n\nLinear Transformation: A fully connected layer that applies a linear transformation to the input tensor.\nNon-linear Activation: After the linear transformation, a non-linear activation function is applied. In this case, we use SiLU (Sigmoid Linear Unit), which is a smooth and differentiable activation function that has shown strong performance in many deep learning models.\nSiLU Activation:\nSiLU, also known as the Swish activation function, is defined as:\n\n[ \\text{SiLU}(x) = x \\cdot \\sigma(x) ]\n\nwhere ( \\sigma(x) ) is the sigmoid function:\n\n[ \\sigma(x) = \\frac{1}{1 + e^{-x}} ]\n\nThis activation is differentiable and allows for smooth gradients, making it particularly well-suited for deep networks.","metadata":{}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        # Initialize the first linear layer: Input -> Hidden layer\n        self.fc1 = nn.Linear(config['emb_dim'], config['hidden_dim'], bias=False)\n        \n        # Initialize the second linear layer: Input -> Hidden layer (to be used in multiplication later)\n        self.fc2 = nn.Linear(config['emb_dim'], config['hidden_dim'], bias=False)\n        \n        # Initialize the third linear layer: Hidden layer -> Output (back to original dimension)\n        self.fc3 = nn.Linear(config['hidden_dim'], config['emb_dim'], bias=False)\n\n    def forward(self, x):\n        # Pass the input through the first linear layer\n        x1 = self.fc1(x)\n        \n        # Pass the input through the second linear layer\n        x2 = self.fc2(x)\n        \n        # Apply SiLU activation (Sigmoid Linear Unit) to the output of the first linear layer\n        # Multiply the result with the output of the second linear layer\n        # This operation introduces element-wise multiplication between activations and transformed values\n        x = F.silu(x1) * x2 \n        \n        # Pass the result through the third linear layer to return to the original dimension\n        x = self.fc3(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:03:36.802379Z","iopub.execute_input":"2025-09-08T09:03:36.802666Z","iopub.status.idle":"2025-09-08T09:03:36.808165Z","shell.execute_reply.started":"2025-09-08T09:03:36.802644Z","shell.execute_reply":"2025-09-08T09:03:36.807302Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Step 1: Define the sequence length and head dimension\n# The sequence length represents the number of tokens (positions) in the sequence\n# The head dimension represents the number of embedding dimensions for each token\nsequence_length = 1024  # Length of the sequence (number of tokens)\nhead_dim = 64           # Dimension of each token's embedding vector\ntheta_base = 10000.0    # Base value used to calculate positional frequencies\n\n# Step 2: Create the position tensor `m` representing the position of each token in the sequence\n# `m` will have values from 0 to sequence_length - 1, representing the position of each token\n# Mathematically, `m` is a vector {0, 1, 2, ..., sequence_length-1}\nm = torch.arange(sequence_length).float()  # Positions in the sequence\n\n# Step 3: Calculate the theta values using the formula from the Reformer paper\n# We are calculating theta_i = 10000^(-2(i-1)/dim) for i = 1, 2, ..., head_dim/2\n# The `theta_numerator` represents the indices i for every alternate value (i.e., 0, 2, 4, ..., head_dim-2)\ntheta_numerator = torch.arange(0, head_dim, 2).float()  # Indices for every alternate value\ntheta = 1.0 / (theta_base ** (theta_numerator / head_dim))  # Compute the theta values for each embedding dimension\n\n# Step 4: Compute the outer product between `m` (positions) and `theta` (frequencies)\n# The outer product between `m` and `theta` gives us a matrix where each element is the product of position and frequency\n# Mathematically, freqs(i, j) = m_i * theta_j for each position i and dimension j\nfreqs = torch.outer(m, theta).float()  # Outer product between m and theta, resulting in positional frequencies\n\n# Step 5: Convert the positional frequencies to complex numbers in polar form\n# In polar form, a complex number is represented as R * exp(i * theta), where R = 1 (magnitude)\n# We use `torch.polar` to create complex numbers with a magnitude of 1 and the computed frequencies as angles\nfreqs_complex = torch.polar(torch.ones_like(freqs), freqs)  # Convert frequencies to complex numbers (polar form)\n\n# Now, `freqs_complex` contains the complex numbers representing the rotational encodings for each position\nprint(freqs_complex)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:05:57.872221Z","iopub.execute_input":"2025-09-08T09:05:57.872790Z","iopub.status.idle":"2025-09-08T09:05:57.910232Z","shell.execute_reply.started":"2025-09-08T09:05:57.872764Z","shell.execute_reply":"2025-09-08T09:05:57.909472Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n          ...,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n          1.0000+0.0000e+00j],\n        [ 0.5403+8.4147e-01j,  0.7318+6.8156e-01j,  0.8460+5.3317e-01j,\n          ...,  1.0000+2.3714e-04j,  1.0000+1.7783e-04j,\n          1.0000+1.3335e-04j],\n        [-0.4161+9.0930e-01j,  0.0709+9.9748e-01j,  0.4315+9.0213e-01j,\n          ...,  1.0000+4.7427e-04j,  1.0000+3.5566e-04j,\n          1.0000+2.6670e-04j],\n        ...,\n        [-0.9998+1.7612e-02j,  0.6164-7.8744e-01j, -0.7242+6.8960e-01j,\n          ...,  0.9708+2.3976e-01j,  0.9836+1.8057e-01j,\n          0.9907+1.3573e-01j],\n        [-0.5550-8.3182e-01j,  0.9877-1.5612e-01j, -0.9803+1.9732e-01j,\n          ...,  0.9708+2.3999e-01j,  0.9835+1.8074e-01j,\n          0.9907+1.3586e-01j],\n        [ 0.4001-9.1649e-01j,  0.8292+5.5900e-01j, -0.9346-3.5578e-01j,\n          ...,  0.9707+2.4022e-01j,  0.9835+1.8092e-01j,\n          0.9907+1.3600e-01j]])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create input tensor\nx = torch.linspace(-5, 5, steps=100)\n\n# SiLU implementation from scratch\ndef silu(x):\n    return x * torch.sigmoid(x)\n\n# Calculate activations\nsilu_output = silu(x)\nrelu_output = F.relu(x)\ngelu_output = F.gelu(x)\n\n# Plot the results\nplt.figure(figsize=(10, 6))\nplt.plot(x.numpy(), silu_output.numpy(), label='SiLU', color='b')\nplt.plot(x.numpy(), relu_output.numpy(), label='ReLU', color='g')\nplt.plot(x.numpy(), gelu_output.numpy(), label='GELU', color='m')\nplt.title('Comparison of Activation Functions: SiLU, ReLU, GELU')\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:03:39.650231Z","iopub.execute_input":"2025-09-08T09:03:39.650890Z","iopub.status.idle":"2025-09-08T09:03:39.958628Z","shell.execute_reply.started":"2025-09-08T09:03:39.650859Z","shell.execute_reply":"2025-09-08T09:03:39.957780Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def apply_rotary_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor, device: str):\n    # Separate the last dimension pairs of two values, representing the real and imaginary parts of the complex number\n    # Two consecutive values will become a single complex number\n    # (B, Seq_Len, H, Head_Dim) -> (B, Seq_Len, H, Head_Dim/2)\n    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n    # Reshape the freqs_complex tensor to match the shape of the x_complex tensor. So we need to add the batch dimension and the head dimension\n    # (Seq_Len, Head_Dim/2) --> (1, Seq_Len, 1, Head_Dim/2)\n    freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n    # Multiply each complex number in the x_complex tensor by the corresponding complex number in the freqs_complex tensor\n    # Which results in the rotation of the complex number as shown in the Figure 1 of the paper\n    # (B, Seq_Len, H, Head_Dim/2) * (1, Seq_Len, 1, Head_Dim/2) = (B, Seq_Len, H, Head_Dim/2)\n    x_rotated = x_complex * freqs_complex\n    # Convert the complex number back to the real number\n    # (B, Seq_Len, H, Head_Dim/2) -> (B, Seq_Len, H, Head_Dim/2, 2)\n    x_out = torch.view_as_real(x_rotated)\n    # (B, Seq_Len, H, Head_Dim/2, 2) -> (B, Seq_Len, H, Head_Dim)\n    x_out = x_out.reshape(*x.shape)\n    return x_out.type_as(x).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:07:00.591288Z","iopub.execute_input":"2025-09-08T09:07:00.591571Z","iopub.status.idle":"2025-09-08T09:07:00.596679Z","shell.execute_reply.started":"2025-09-08T09:07:00.591553Z","shell.execute_reply":"2025-09-08T09:07:00.595834Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# THIS IS A COMPACT IMPLEMENTATION OF THE SAME CELL ABOVE \ndef precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):\n    # As written in the paragraph 3.2.2 of the paper\n    # >> In order to generalize our results in 2D to any xi  Rd where **d is even**, [...]\n    assert head_dim % 2 == 0, \"Dimension must be divisible by 2\"\n    # Build the theta parameter\n    # According to the formula theta_i = 10000^(-2(i-1)/dim) for i = [1, 2, ... dim/2]\n    # Shape: (Head_Dim / 2)\n    theta_numerator = torch.arange(0, head_dim, 2).float()\n    # Shape: (Head_Dim / 2)\n    theta = 1.0 / (theta ** (theta_numerator / head_dim)).to(device) # (Dim / 2)\n    # Construct the positions (the \"m\" parameter)\n    # Shape: (Seq_Len)\n    m = torch.arange(seq_len, device=device)\n    # Multiply each theta by each position using the outer product.\n    # Shape: (Seq_Len) outer_product* (Head_Dim / 2) -> (Seq_Len, Head_Dim / 2)\n    freqs = torch.outer(m, theta).float()\n    # We can compute complex numbers in the polar form c = R * exp(m * theta), where R = 1 as follows:\n    # (Seq_Len, Head_Dim / 2) -> (Seq_Len, Head_Dim / 2)\n    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n    return freqs_complex","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:07:29.121006Z","iopub.execute_input":"2025-09-08T09:07:29.121675Z","iopub.status.idle":"2025-09-08T09:07:29.126461Z","shell.execute_reply.started":"2025-09-08T09:07:29.121651Z","shell.execute_reply":"2025-09-08T09:07:29.125767Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Example input\nbatch_size = 4\nseq_len = 10\nhead_dim = 16\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Generate random input tensor (batch_size, seq_len, num_heads, head_dim)\nx = torch.randn(batch_size, seq_len, 8, head_dim, device=device)\n\n# Precompute frequency complex numbers\nfreqs_complex = precompute_theta_pos_frequencies(head_dim, seq_len, device)\n\n# Apply rotary position embeddings\nx_rot = apply_rotary_embeddings(x, freqs_complex, device)\n\nprint(\"Input shape:\", x.shape)\nprint(\"Rotated shape:\", x_rot.shape)   \nprint(x_rot[:5]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:07:31.104710Z","iopub.execute_input":"2025-09-08T09:07:31.105284Z","iopub.status.idle":"2025-09-08T09:07:31.473147Z","shell.execute_reply.started":"2025-09-08T09:07:31.105257Z","shell.execute_reply":"2025-09-08T09:07:31.472481Z"}},"outputs":[{"name":"stdout","text":"Input shape: torch.Size([4, 10, 8, 16])\nRotated shape: torch.Size([4, 10, 8, 16])\ntensor([[[[ 0.4853,  0.0845, -0.8191,  ...,  0.0566, -1.6677,  0.0418],\n          [-0.4706,  0.8150, -1.1517,  ..., -1.2831,  0.0746, -2.3797],\n          [-0.0695,  0.9716,  2.6051,  ...,  0.2786, -0.0635,  1.1197],\n          ...,\n          [ 0.8343, -0.8970, -0.3091,  ..., -1.7149, -0.9758, -0.1683],\n          [ 0.4093,  0.0781,  1.8028,  ..., -0.5999,  1.4788,  1.7273],\n          [-2.2206,  0.5006, -0.9911,  ...,  0.3703, -0.0637, -0.7204]],\n\n         [[ 0.2289,  1.5302,  0.9503,  ..., -0.4908,  0.7607,  2.0575],\n          [ 1.3200, -0.7677, -3.3583,  ...,  0.6447,  0.2456,  0.7898],\n          [ 0.5827,  1.0043,  0.3658,  ..., -0.5532, -0.4631,  0.4345],\n          ...,\n          [ 0.2650,  0.8098, -0.4660,  ..., -0.6597, -0.3532,  0.1453],\n          [ 0.8254,  0.2598,  0.5432,  ..., -0.8409,  1.2401, -1.3810],\n          [ 0.2830, -1.8397,  0.0167,  ...,  0.6197, -1.2532,  0.6989]],\n\n         [[-1.4741,  0.5097,  0.9086,  ..., -0.1709,  0.2286, -1.0126],\n          [-1.1471,  0.6563,  0.9370,  ..., -1.2328, -1.1486, -0.6767],\n          [ 0.9847,  0.7954, -0.7980,  ..., -0.9131, -1.7121,  0.4534],\n          ...,\n          [ 0.3258, -0.0402,  0.7000,  ...,  0.8606,  0.4962, -1.4184],\n          [ 0.2841, -0.4005, -0.5968,  ..., -2.3138,  0.7231, -0.1303],\n          [ 0.6751,  0.2828,  1.9818,  ...,  0.1641,  0.4179, -1.1742]],\n\n         ...,\n\n         [[ 0.2801, -0.3200,  0.9776,  ..., -1.4079, -0.2244, -0.3935],\n          [ 0.2782,  0.1331,  0.9178,  ..., -1.3074, -1.9699, -0.9317],\n          [-0.4659,  0.9243, -1.1027,  ..., -0.1144,  0.4253,  0.3336],\n          ...,\n          [-0.5521, -0.8692,  2.0104,  ..., -1.3022, -0.1001,  1.3693],\n          [-0.0274,  0.4580, -0.7823,  ..., -1.9798, -1.2702,  0.5589],\n          [ 0.4141,  0.0998,  0.1220,  ..., -0.8222,  0.9826, -1.6021]],\n\n         [[ 0.3135, -1.5055,  1.4781,  ...,  0.1652, -0.1033, -1.7706],\n          [-1.2203, -1.4458, -0.8377,  ...,  0.2054, -0.3862,  0.2365],\n          [ 0.1611,  0.5624, -0.3717,  ...,  0.7803, -0.6698,  0.2891],\n          ...,\n          [-1.1172,  1.0884, -0.1537,  ...,  0.1231,  0.6995, -0.6875],\n          [ 1.1548, -0.7769,  0.2678,  ...,  0.0871,  0.0466, -0.5927],\n          [ 0.1290, -0.0898,  0.5514,  ...,  0.9298, -0.3321, -0.8738]],\n\n         [[ 0.4637, -0.7551,  0.6807,  ...,  1.0832, -1.7508, -0.9478],\n          [-0.0790, -0.6658, -0.7584,  ...,  0.5286, -0.2735,  0.2630],\n          [-2.2927, -0.3273, -0.1984,  ..., -1.3403,  2.8708, -0.8155],\n          ...,\n          [-0.6783,  1.8920, -0.2501,  ..., -0.5184,  0.4069,  0.4844],\n          [-0.8098,  0.0144,  0.4185,  ..., -1.0889,  0.0673, -1.5811],\n          [-0.3084, -0.0523,  0.7348,  ..., -0.3109,  2.4120,  2.1091]]],\n\n\n        [[[-0.0368, -0.5260,  0.6419,  ..., -0.6600, -1.1183, -0.9174],\n          [ 1.4063, -1.1095,  0.4780,  ...,  0.5994,  0.3168, -1.1023],\n          [ 1.9776, -0.9367, -1.1100,  ...,  0.2551,  0.9117,  0.4434],\n          ...,\n          [ 1.2157,  0.9732,  0.0418,  ...,  0.0749, -0.4818, -0.1085],\n          [-0.7565,  0.2534,  0.5914,  ..., -0.6265,  1.5033,  0.1477],\n          [ 0.8589, -0.8308, -0.4129,  ...,  0.2122,  0.6823,  1.4324]],\n\n         [[ 1.0014,  1.1606, -0.3200,  ...,  0.5094, -0.5889,  1.2812],\n          [ 1.1212,  0.6360, -2.0072,  ...,  1.4353, -2.0278, -0.9470],\n          [-0.6129, -0.6190, -0.8901,  ..., -1.7228, -0.2010, -0.8559],\n          ...,\n          [-0.0834, -0.2828, -0.8644,  ..., -0.3173,  1.1168, -1.8428],\n          [ 0.7749,  0.2956,  1.0580,  ..., -1.4492,  0.4606, -1.1431],\n          [-2.2150, -1.1386,  0.1630,  ...,  0.3107,  0.2089,  0.4439]],\n\n         [[ 0.2403,  1.3866,  0.3894,  ...,  0.9920, -0.9023,  0.4888],\n          [ 0.7119,  0.1480,  1.4266,  ...,  0.4962, -1.3652,  0.9934],\n          [-0.1499,  1.2864, -1.6079,  ...,  1.6133,  0.2394, -0.3724],\n          ...,\n          [-1.0012, -0.9807, -0.4894,  ..., -1.1265,  0.2180,  0.5056],\n          [-0.5023, -1.5288,  0.1990,  ...,  0.2011, -0.8441,  0.1055],\n          [ 1.4582,  0.6918, -0.5976,  ..., -0.2297, -1.6132, -0.6727]],\n\n         ...,\n\n         [[-0.5005, -0.5875,  1.7058,  ..., -0.3821, -0.1600,  0.1696],\n          [-1.8645, -0.4699, -0.1663,  ...,  0.2060, -0.1094,  0.0231],\n          [-0.2606, -0.2915,  0.1679,  ...,  0.2233, -0.4004,  0.8182],\n          ...,\n          [ 1.2037, -0.9571,  1.1201,  ...,  0.5597,  1.5384, -0.9595],\n          [ 1.1704, -0.2962,  0.4642,  ...,  0.8457, -0.0176, -0.1757],\n          [-1.4092, -0.6067,  0.6918,  ...,  0.4860, -1.0334, -0.9413]],\n\n         [[ 0.4088,  0.2455, -1.9624,  ...,  0.5244,  0.1374,  0.1987],\n          [-0.7498, -0.4226, -0.3277,  ..., -0.0863,  0.9747, -1.1715],\n          [ 2.6670,  1.6820, -1.9856,  ...,  0.9035,  0.7611,  0.1327],\n          ...,\n          [-0.6729, -1.6567, -1.6019,  ...,  0.1263, -0.1840,  0.7259],\n          [ 1.0361, -1.3268, -0.7132,  ..., -0.0366, -0.5594, -0.9412],\n          [-0.4915, -0.5452,  1.4242,  ..., -1.2189,  0.7959,  1.2396]],\n\n         [[-1.9555, -0.9466,  1.4084,  ...,  0.6734,  1.3682,  0.4759],\n          [ 0.5582,  1.8912,  0.6023,  ...,  0.8210,  1.3044, -1.3610],\n          [-1.7172, -1.2156,  0.1796,  ..., -0.7554,  0.2805,  0.0881],\n          ...,\n          [ 0.2651,  0.2895,  0.2243,  ..., -0.4985,  1.5910, -0.0900],\n          [ 0.7908,  2.6204,  0.0082,  ...,  0.0137,  0.0071, -0.0285],\n          [-1.6344,  1.3274, -0.1713,  ...,  1.6115,  1.6258, -0.0783]]],\n\n\n        [[[ 0.6331, -0.2918,  1.0310,  ...,  0.9632, -1.0379, -0.4728],\n          [-0.7398, -0.4476,  0.1908,  ..., -0.4632,  0.7896, -0.1602],\n          [ 0.1369,  0.7837,  0.6058,  ..., -0.7856,  1.4692,  0.1208],\n          ...,\n          [-0.3113,  0.2465, -0.1894,  ..., -0.2255, -0.5643,  0.3821],\n          [ 0.5727, -0.0583,  0.4791,  ..., -0.3319,  0.3579,  1.2048],\n          [ 0.3710,  0.9158, -1.7414,  ...,  0.1526, -0.4317, -1.9576]],\n\n         [[-0.7239,  0.0607, -0.7775,  ...,  0.8205,  1.1459, -1.2728],\n          [-0.6291,  0.4009,  0.9266,  ..., -0.3281, -0.6415,  1.3311],\n          [-0.3233, -0.8955, -0.6846,  ..., -0.7363,  0.0304,  0.3412],\n          ...,\n          [-0.1272, -1.6687,  0.2318,  ...,  1.5786,  0.7634, -2.6899],\n          [ 0.6522, -0.3596, -0.8873,  ...,  0.2885, -0.6492, -1.7119],\n          [ 0.4571, -0.5643, -0.8533,  ...,  0.7959,  0.7444, -0.7893]],\n\n         [[-1.0852,  0.0603,  0.2575,  ..., -1.6160,  0.0405, -1.3693],\n          [-0.0298, -0.1379,  0.0466,  ...,  1.7113,  0.9191,  1.6071],\n          [ 0.2270, -0.7778, -1.5718,  ...,  0.3156, -1.5135,  0.8945],\n          ...,\n          [ 1.9936, -1.1078,  0.4628,  ..., -0.0644, -0.5714, -0.2095],\n          [-1.0835,  0.5399, -2.1370,  ..., -0.4070,  2.3135, -1.0641],\n          [-0.3231, -0.0124,  1.6203,  ...,  1.0231, -0.0590, -0.7185]],\n\n         ...,\n\n         [[ 0.0841,  0.8284,  0.8750,  ...,  1.0933,  0.1413, -1.0799],\n          [ 0.3918,  0.7625,  0.2379,  ..., -0.5948, -0.0744, -0.2007],\n          [ 0.0197, -1.0229, -0.3463,  ...,  0.2730,  2.0778,  0.8996],\n          ...,\n          [-2.5385,  1.5711,  0.7245,  ...,  1.0831, -1.4512, -1.5157],\n          [ 0.0886,  0.0943,  1.4884,  ..., -0.1146, -0.3621,  1.7727],\n          [ 0.5680,  1.2516, -0.4001,  ...,  0.9592,  0.6718,  0.4081]],\n\n         [[ 1.2421, -0.2565, -1.1805,  ..., -0.2630,  0.3710,  0.3528],\n          [ 1.2574,  0.0486,  0.4697,  ..., -0.8146, -1.4607, -1.8384],\n          [-1.0329, -0.3300,  1.0199,  ...,  0.8804, -0.4794, -0.5154],\n          ...,\n          [ 1.0926, -1.2457,  0.4950,  ...,  0.4719, -0.8847, -0.1429],\n          [-0.2461,  1.3336, -0.5879,  ...,  0.5656, -0.6678, -2.3121],\n          [-1.1104,  0.9981, -0.3352,  ...,  0.7812,  0.4592,  0.3488]],\n\n         [[-0.9892, -1.4651,  0.3638,  ...,  3.0025, -0.1568, -0.5699],\n          [-0.2632, -0.7527,  0.5770,  ..., -1.9833,  0.1986, -1.2138],\n          [ 0.9797, -1.6495, -1.2930,  ..., -1.2707, -0.2506, -0.6120],\n          ...,\n          [ 0.5281, -1.6315, -0.8224,  ...,  0.5056, -1.0884, -2.3964],\n          [ 0.6025, -0.3538, -1.6119,  ...,  0.7651,  0.4196,  2.4546],\n          [ 1.7859,  0.5888,  0.4180,  ...,  0.1563, -0.2120, -1.5506]]],\n\n\n        [[[-0.1807, -0.0152, -0.4137,  ..., -0.3569,  1.2661, -1.0444],\n          [ 0.1609,  1.3846,  0.0747,  ..., -0.8509,  1.5804, -0.3911],\n          [ 0.0343, -1.2838, -0.9660,  ...,  0.4798, -2.6625,  0.0559],\n          ...,\n          [-0.3810,  0.9537,  1.1043,  ...,  0.3379, -0.8820,  0.4312],\n          [-0.8189, -0.7312,  0.4099,  ...,  0.9352, -1.2562,  0.4149],\n          [ 2.4910, -0.5968, -0.2990,  ...,  1.0831, -0.8145, -0.8577]],\n\n         [[-1.2710, -0.6994,  3.0319,  ..., -0.1465, -1.3911,  0.3469],\n          [-0.2614,  0.6580, -1.0591,  ...,  0.8106,  0.1118,  0.5004],\n          [ 1.1169, -0.7162,  1.2183,  ...,  0.5876,  0.5507, -0.6249],\n          ...,\n          [-0.7178,  1.0058,  0.8575,  ..., -0.3742,  1.6476,  0.4418],\n          [ 0.8164, -1.6734, -0.2847,  ...,  0.6296,  0.1302,  0.5830],\n          [-1.0978,  0.6108,  1.5261,  ...,  2.0891,  1.8807, -0.7945]],\n\n         [[-1.7692, -0.5708,  0.4429,  ...,  0.4106,  1.1445,  0.6352],\n          [-0.4534, -1.2965,  1.7843,  ...,  0.5071,  1.1785, -1.0824],\n          [ 0.5369,  0.6596,  0.6208,  ..., -0.4576, -1.2077, -0.3011],\n          ...,\n          [-0.7677,  0.2973,  1.4022,  ..., -0.8340,  0.6047,  1.1968],\n          [-1.4403,  0.5927,  1.4368,  ...,  0.0123, -0.6260, -0.2983],\n          [ 0.9097, -1.4622, -0.7069,  ...,  0.0257,  0.0068, -1.7282]],\n\n         ...,\n\n         [[ 0.3674,  0.9370, -1.6163,  ..., -1.1059,  0.3447,  1.5782],\n          [ 1.0030,  0.1043,  1.1671,  ..., -0.7263, -0.0543, -2.4590],\n          [-0.5691, -1.6721, -1.2470,  ...,  0.1606,  0.6358,  0.0126],\n          ...,\n          [-1.3009, -0.5454,  1.4864,  ..., -1.7198, -0.9699,  0.5694],\n          [ 0.3970, -0.0987, -2.4676,  ..., -0.1320, -1.2003,  0.3756],\n          [ 1.1964,  1.2238,  0.7126,  ...,  0.0901, -0.2683, -0.4100]],\n\n         [[ 1.6628, -1.5520,  0.7758,  ..., -0.7780, -1.2324,  0.3439],\n          [ 1.1966, -0.8138,  0.3347,  ..., -0.6772,  0.6190, -0.4846],\n          [ 1.0202,  1.1171, -0.3066,  ..., -0.3304, -0.6052,  0.1340],\n          ...,\n          [-0.9856,  1.7144,  2.1034,  ..., -0.4541,  2.3842,  0.1935],\n          [ 0.7147,  1.3767, -0.3538,  ...,  0.0272, -0.2314, -1.2957],\n          [ 0.1477, -1.3404, -0.4369,  ..., -0.0245,  0.7817, -0.3500]],\n\n         [[-0.8058, -1.4606,  0.6757,  ...,  2.1239,  0.2995, -0.2265],\n          [ 0.1433, -0.2431,  0.0666,  ...,  0.1917,  1.4984,  0.3464],\n          [-0.8714, -0.2481, -1.1445,  ...,  1.5239,  0.3508,  1.3109],\n          ...,\n          [ 0.8692,  0.4943, -1.4052,  ...,  0.3665,  0.7097,  0.0240],\n          [ 0.5615, -1.4133, -0.0844,  ...,  0.9286,  1.7683, -0.9311],\n          [ 0.7878, -0.0320,  0.6987,  ...,  1.2988,  0.3128, -0.9412]]]],\n       device='cuda:0')\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Grouped Query Attention (GQA)\nGrouped Query Attention (GQA) is a variation of the standard Multi-Head Attention (MHA) mechanism used in transformer models. Instead of having multiple attention heads (as in MHA), GQA organizes queries into a smaller number of query groups, while the keys and values are not grouped. This approach reduces computational complexity while retaining expressive power.\n\nEfficient RoPE\n\nKey Components of GQA:\nQuery Grouping:\n\nQueries are divided into groups, leading to fewer query computations compared to MHA.\nKeys and values are not grouped, allowing them to attend to all input tokens.\nEfficiency:\n\nReduces the memory and compute requirements of the attention mechanism compared to MHA.\nParticularly advantageous for large models or when memory efficiency is critical.\nDifferences Between GQA and MHA:\nFeature\tMulti-Head Attention (MHA)\tGrouped Query Attention (GQA)\nQuery Organization\tMultiple independent attention heads\tQueries are grouped into fewer groups\nKey & Value Behavior\tSeparate keys and values for each attention head\tShared keys and values across query groups\nComplexity\tHigher due to multiple heads\tLower due to reduced number of query groups\nUse Case\tSuitable for tasks requiring high expressiveness\tSuitable for memory-efficient scenarios\nPractical Implication:\nWhile MHA excels in providing diverse attention mechanisms across multiple heads, GQA trades off some of this flexibility to improve efficiency. It is commonly used in modern large-scale transformer architectures, like the LLaMA series, where scaling efficiency is critical without significantly compromising performance.","metadata":{}},{"cell_type":"code","source":"class SharedBuffers:\n    # Dictionary to store precomputed buffers\n    _buffers = {}\n\n    @staticmethod\n    def get_buffers(context_length, head_dim, rope_base, freq_config, dtype=torch.float32, device=\"cpu\"):\n        \n        # Unique key based on the provided parameters to identify buffer configurations\n        key = (\n            context_length,\n            head_dim,\n            rope_base,\n            tuple(freq_config.values()) if freq_config else freq_config,\n            dtype\n        )\n\n        # Check if the buffers for this configuration already exist\n        if key not in SharedBuffers._buffers:\n            # If not, create the buffers\n\n            # 1. Create a causal mask (upper triangular matrix)\n            # Ensures future tokens do not attend to past tokens in the sequence\n            mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n\n            # 2. Compute RoPE frequencies using a custom precompute function\n            # This function is assumed to generate complex frequencies for positional encoding\n            freqs_complex = precompute_theta_pos_frequencies(\n                head_dim, context_length, device, rope_base\n            )\n\n            # 3. Convert the RoPE frequencies to the desired data type if specified\n            if dtype is not None:\n                freqs_complex = freqs_complex.to(dtype)\n\n            # 4. Cache the mask and frequencies in the shared dictionary\n            SharedBuffers._buffers[key] = (mask, freqs_complex)\n\n        # Return the cached or newly created buffers\n        return SharedBuffers._buffers[key]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:10:03.383823Z","iopub.execute_input":"2025-09-08T09:10:03.384348Z","iopub.status.idle":"2025-09-08T09:10:03.390300Z","shell.execute_reply.started":"2025-09-08T09:10:03.384321Z","shell.execute_reply":"2025-09-08T09:10:03.389288Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class GroupedQueryAttention(nn.Module):\n    \n    def __init__(\n            self, d_in, d_out, context_length, num_heads,\n            num_kv_groups, rope_base=10_000, rope_config=None,\n            dtype=None, device='cpu'\n        ):\n        super().__init__()\n        \n        # Validations for divisibility constraints\n        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n\n        # Initialization of key attributes\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads  # Dimension per head\n        self.device = device  # Store device for tensor operations\n\n        # Linear transformations for keys, values, and queries\n        self.W_key = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n        self.W_value = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n        self.W_query = nn.Linear(d_in, d_out, bias=False, dtype=dtype)\n\n        # Output projection layer for combining attention results\n        self.out_proj = nn.Linear(d_out, d_out, bias=False, dtype=dtype)\n\n        # Number of heads per group\n        self.num_kv_groups = num_kv_groups\n        self.group_size = num_heads // num_kv_groups\n\n        # Fetch shared buffers for causal masks and RoPE frequencies\n        mask, freqs_complex = SharedBuffers.get_buffers(\n            context_length, self.head_dim, rope_base, rope_config, dtype=dtype, device=device\n        )\n        self.register_buffer(\"mask\", mask)  # Cache causal mask as a buffer\n        self.register_buffer(\"freqs_complex\", freqs_complex)  # Cache RoPE frequencies as a buffer\n\n    def forward(self, x):\n        # x: Input tensor of shape (batch_size, num_tokens, d_in)\n        b, num_tokens, d_in = x.shape\n\n        # Compute keys, values, and queries\n        queries = self.W_query(x)  # Shape: (b, num_tokens, d_out)\n        keys = self.W_key(x)  # Shape: (b, num_tokens, num_kv_groups * head_dim)\n        values = self.W_value(x)  # Shape: (b, num_tokens, num_kv_groups * head_dim)\n\n        # Reshape keys, values, and queries for attention heads\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim)\n        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim)\n\n        # Transpose for compatibility with attention computation\n        keys = keys.transpose(1, 2)  # Shape: (b, num_kv_groups, num_tokens, head_dim)\n        values = values.transpose(1, 2)  # Shape: (b, num_kv_groups, num_tokens, head_dim)\n        queries = queries.transpose(1, 2)  # Shape: (b, num_heads, num_tokens, head_dim)\n\n        # Apply rotary position encoding (RoPE) to keys and queries\n        keys = apply_rotary_embeddings(keys, self.freqs_complex, self.device)\n        queries = apply_rotary_embeddings(queries, self.freqs_complex, self.device)\n\n        # Expand keys and values to match the number of heads\n        keys = keys.repeat_interleave(self.group_size, dim=1)  # Shape: (b, num_heads, num_tokens, head_dim)\n        values = values.repeat_interleave(self.group_size, dim=1)  # Shape: (b, num_heads, num_tokens, head_dim)\n\n        # Compute scaled dot-product attention with a causal mask\n        attn_scores = queries @ keys.transpose(2, 3)  # Shape: (b, num_heads, num_tokens, num_tokens)\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]  # Adjust mask size to current input length\n        attn_scores.masked_fill_(mask_bool, -torch.inf)  # Apply causal mask\n\n        # Normalize scores with softmax\n        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)  # Shape: (b, num_heads, num_tokens, num_tokens)\n\n        # Compute attention output\n        context_vec = (attn_weights @ values).transpose(1, 2)  # Shape: (b, num_tokens, num_heads, head_dim)\n\n        # Combine attention heads into final output shape\n        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)  # Apply optional projection\n\n        return context_vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:10:39.638492Z","iopub.execute_input":"2025-09-08T09:10:39.638765Z","iopub.status.idle":"2025-09-08T09:10:39.651642Z","shell.execute_reply.started":"2025-09-08T09:10:39.638746Z","shell.execute_reply":"2025-09-08T09:10:39.650818Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Llama 3.2 1B\n\nLLAMA32_CONFIG = {\n    \"vocab_size\": 128_256,      # Vocabulary size\n    \"context_length\": 131_072,  # Context length\n    \"emb_dim\": 2048,            # Embedding dimension\n    \"n_heads\": 32,              # Number of attention heads\n    \"n_layers\": 16,             # Number of layers\n    \"hidden_dim\": 8192,         # Size of the intermediate dimension in FeedForward\n    \"n_kv_groups\": 8,           # Key-Value groups for grouped-query attention\n    \"rope_base\": 500_000.0,     # The base in RoPE's \"theta\"\n    \"dtype\": torch.bfloat16,    # Lower-precision dtype to reduce memory usage\n    \"rope_freq\": {              # RoPE frequency scaling\n        \"factor\": 32.0,\n        \"low_freq_factor\": 1.0,\n        \"high_freq_factor\": 4.0,\n        \"original_context_length\": 8192,\n    }\n}\n\n# Llama 3.2 3B\n\n# LLAMA32_CONFIG = {\n#     \"vocab_size\": 128_256,      # Vocabulary size\n#     \"context_length\": 131_072,  # Context length\n#     \"emb_dim\": 3072,            # Embedding dimension\n#     \"n_heads\": 24,              # Number of attention heads\n#     \"n_layers\": 28,             # Number of layers\n#     \"hidden_dim\": 8192,         # Size of the intermediate dimension in FeedForward\n#     \"n_kv_groups\": 8,           # Key-Value groups for grouped-query attention\n#     \"rope_base\": 500_000.0,     # The base in RoPE's \"theta\"\n#     \"dtype\": torch.bfloat16,    # Lower-precision dtype to reduce memory usage\n#     \"rope_freq\": {              # RoPE frequency scaling\n#         \"factor\": 32.0,\n#         \"low_freq_factor\": 1.0,\n#         \"high_freq_factor\": 4.0,\n#         \"original_context_length\": 8192,\n#     }\n# }\n\nLLAMA_SIZE_STR = \"1B\" if LLAMA32_CONFIG[\"emb_dim\"] == 2048 else \"3B\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:12:51.038536Z","iopub.execute_input":"2025-09-08T09:12:51.039285Z","iopub.status.idle":"2025-09-08T09:12:51.044404Z","shell.execute_reply.started":"2025-09-08T09:12:51.039261Z","shell.execute_reply":"2025-09-08T09:12:51.043580Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"old_context_length = LLAMA32_CONFIG[\"context_length\"]\nLLAMA32_CONFIG[\"context_length\"] = 8192\n\n\ndef rescale_theta(theta_old, context_length_old, context_length_new):\n    scaling_factor = context_length_new / context_length_old\n    theta_new = theta_old * scaling_factor\n    return theta_new\n\nLLAMA32_CONFIG[\"rope_base\"] = rescale_theta(\n    LLAMA32_CONFIG[\"rope_base\"],\n    old_context_length,\n    LLAMA32_CONFIG[\"context_length\"]\n)\n\nprint(\"New RoPE theta:\", LLAMA32_CONFIG[\"rope_base\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:13:11.204753Z","iopub.execute_input":"2025-09-08T09:13:11.205049Z","iopub.status.idle":"2025-09-08T09:13:11.210337Z","shell.execute_reply.started":"2025-09-08T09:13:11.205026Z","shell.execute_reply":"2025-09-08T09:13:11.209414Z"}},"outputs":[{"name":"stdout","text":"New RoPE theta: 31250.0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:14:05.989986Z","iopub.execute_input":"2025-09-08T09:14:05.990566Z","iopub.status.idle":"2025-09-08T09:14:05.994248Z","shell.execute_reply.started":"2025-09-08T09:14:05.990533Z","shell.execute_reply":"2025-09-08T09:14:05.993538Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Initialize the first linear layer: projects input embedding to hidden dimension\n        self.fc1 = nn.Linear(config['emb_dim'], config['hidden_dim'], bias=False)\n        \n        # Initialize the second linear layer: creates additional projections for gating mechanism\n        self.fc2 = nn.Linear(config['emb_dim'], config['hidden_dim'], bias=False)\n        \n        # Initialize the third linear layer: maps back from hidden dimension to original embedding dimension\n        self.fc3 = nn.Linear(config['hidden_dim'], config['emb_dim'], bias=False)\n\n    def forward(self, x):\n        # Compute first projection\n        x1 = self.fc1(x)\n        # Compute second projection for gating\n        x2 = self.fc2(x)\n        # Element-wise multiplication after SiLU activation introduces non-linear interactions\n        x = F.silu(x1) * x2 \n        # Project back to the original embedding space\n        x = self.fc3(x)\n        return x\n\n\n# GroupedQueryAttention Class\nclass GroupedQueryAttention(nn.Module):\n    def __init__(\n            self, d_in, d_out, context_length, num_heads,\n            num_kv_groups, rope_base=10_000, rope_config=None,\n            dtype=None, device='cpu'  # Device is specified with a default value\n        ):\n        super().__init__()\n        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n\n        # Initialize essential parameters\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads\n        self.device = device\n\n        # Define linear layers for keys, values, and queries\n        self.W_key = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n        self.W_value = nn.Linear(d_in, num_kv_groups * self.head_dim, bias=False, dtype=dtype)\n        self.W_query = nn.Linear(d_in, d_out, bias=False, dtype=dtype)\n        \n        # Final projection layer after attention\n        self.out_proj = nn.Linear(d_out, d_out, bias=False, dtype=dtype)\n\n        # Configure the grouping structure for keys and values\n        self.num_kv_groups = num_kv_groups\n        self.group_size = num_heads // num_kv_groups\n\n        # Shared buffers for causal mask and rotary embeddings\n        mask, freqs_complex = SharedBuffers.get_buffers(\n            context_length, self.head_dim, rope_base, rope_config, dtype=dtype, device=device\n        )\n        self.register_buffer(\"mask\", mask)\n        self.register_buffer(\"freqs_complex\", freqs_complex)\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n\n        # Compute queries, keys, and values\n        queries = self.W_query(x)\n        keys = self.W_key(x)\n        values = self.W_value(x)\n\n        # Reshape to support multi-head processing\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim)\n        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim)\n\n        # Transpose for compatibility with attention computation\n        keys = keys.transpose(1, 2)\n        values = values.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n\n        # Apply rotary embeddings for positional information\n        keys = apply_rotary_embeddings(keys, self.freqs_complex, self.device)\n        queries = apply_rotary_embeddings(queries, self.freqs_complex, self.device)\n\n        # Expand keys and values to align with query groups\n        keys = keys.repeat_interleave(self.group_size, dim=1)\n        values = values.repeat_interleave(self.group_size, dim=1)\n\n        # Compute attention scores and apply causal mask\n        attn_scores = queries @ keys.transpose(2, 3)\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n\n        # Normalize attention scores and compute weighted sum of values\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        context_vec = (attn_weights @ values).transpose(1, 2)\n\n        # Combine heads and apply final projection\n        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)\n        return context_vec\n\n\n# TransformerBlock Class\nclass TransformerBlock(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Initialize multi-head attention layer\n        self.att = GroupedQueryAttention(\n            d_in=config[\"emb_dim\"],\n            d_out=config[\"emb_dim\"],\n            context_length=config[\"context_length\"],\n            num_heads=config[\"n_heads\"],\n            num_kv_groups=config[\"n_kv_groups\"],\n            rope_base=config[\"rope_base\"],\n            rope_config=config[\"rope_freq\"],\n            dtype=config[\"dtype\"]\n        )\n        \n        # Initialize feedforward network\n        self.ff = FeedForward(config)\n        \n        # Layer normalization layers\n        self.norm1 = nn.RMSNorm(config['emb_dim'])\n        self.norm2 = nn.RMSNorm(config['emb_dim'])\n\n    def forward(self, x):\n        # Apply attention with residual connection\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x.to(torch.bfloat16))\n        x = x + shortcut\n        \n        # Apply feedforward network with residual connection\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x.to(torch.bfloat16))\n        x = x + shortcut\n        return x\n\n\n# Llama3 Class\nclass Llama3(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Token embedding layer to transform input tokens to dense vectors\n        self.token_embedding = nn.Embedding(\n            config['vocab_size'], config['emb_dim'], dtype=config['dtype']\n        )\n        \n        # Stack of transformer blocks\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(config) for _ in range(config['n_layers'])]\n        )\n        \n        # Final layer normalization\n        self.final_norm = nn.RMSNorm(config['emb_dim'])\n        \n        # Output projection to vocabulary size\n        self.out_head = nn.Linear(\n            config['emb_dim'], config['vocab_size'], bias=False, dtype=config['dtype']\n        )\n\n    def forward(self, x):\n        # Convert token indices to embeddings\n        tok_emb = self.token_embedding(x)\n        x = tok_emb\n        \n        # Pass through transformer layers\n        x = self.trf_blocks(tok_emb)\n        \n        # Normalize and project to logits\n        x = self.final_norm(x)\n        logits = self.out_head(x.to(torch.bfloat16))\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:15:23.078597Z","iopub.execute_input":"2025-09-08T09:15:23.079250Z","iopub.status.idle":"2025-09-08T09:15:23.095297Z","shell.execute_reply.started":"2025-09-08T09:15:23.079228Z","shell.execute_reply":"2025-09-08T09:15:23.094469Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(LLAMA32_CONFIG)\nmodel = Llama3(LLAMA32_CONFIG)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:15:31.123451Z","iopub.execute_input":"2025-09-08T09:15:31.124090Z","iopub.status.idle":"2025-09-08T09:15:51.306723Z","shell.execute_reply.started":"2025-09-08T09:15:31.124060Z","shell.execute_reply":"2025-09-08T09:15:51.305941Z"}},"outputs":[{"name":"stdout","text":"{'vocab_size': 128256, 'context_length': 8192, 'emb_dim': 2048, 'n_heads': 32, 'n_layers': 16, 'hidden_dim': 8192, 'n_kv_groups': 8, 'rope_base': 31250.0, 'dtype': torch.bfloat16, 'rope_freq': {'factor': 32.0, 'low_freq_factor': 1.0, 'high_freq_factor': 4.0, 'original_context_length': 8192}}\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3857862455.py:33: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /pytorch/aten/src/ATen/native/Copy.cpp:308.)\n  freqs_complex = freqs_complex.to(dtype)\n","output_type":"stream"},{"name":"stdout","text":"Llama3(\n  (token_embedding): Embedding(128256, 2048)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (1): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (2): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (3): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (4): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (5): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (6): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (7): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (8): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (9): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (10): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (11): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (12): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (13): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (14): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n    (15): TransformerBlock(\n      (att): GroupedQueryAttention(\n        (W_key): Linear(in_features=2048, out_features=512, bias=False)\n        (W_value): Linear(in_features=2048, out_features=512, bias=False)\n        (W_query): Linear(in_features=2048, out_features=2048, bias=False)\n        (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n      )\n      (ff): FeedForward(\n        (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc2): Linear(in_features=2048, out_features=8192, bias=False)\n        (fc3): Linear(in_features=8192, out_features=2048, bias=False)\n      )\n      (norm1): RMSNorm((2048,), eps=None, elementwise_affine=True)\n      (norm2): RMSNorm((2048,), eps=None, elementwise_affine=True)\n    )\n  )\n  (final_norm): RMSNorm((2048,), eps=None, elementwise_affine=True)\n  (out_head): Linear(in_features=2048, out_features=128256, bias=False)\n)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(model.trf_blocks[0].att.mask is model.trf_blocks[-1].att.mask)\nprint(model.trf_blocks[0].att.freqs_complex is model.trf_blocks[-1].att.freqs_complex)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:16:26.954477Z","iopub.execute_input":"2025-09-08T09:16:26.954969Z","iopub.status.idle":"2025-09-08T09:16:26.959472Z","shell.execute_reply.started":"2025-09-08T09:16:26.954946Z","shell.execute_reply":"2025-09-08T09:16:26.958599Z"}},"outputs":[{"name":"stdout","text":"True\nTrue\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total number of parameters: {total_params:,}\")\n\n# Account for weight tying\ntotal_params_normalized = total_params - model.token_emedding.weight.numel()\nprint(f\"\\nTotal number of unique parameters: {total_params_normalized:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:16:50.182043Z","iopub.execute_input":"2025-09-08T09:16:50.182310Z","iopub.status.idle":"2025-09-08T09:16:50.195718Z","shell.execute_reply.started":"2025-09-08T09:16:50.182291Z","shell.execute_reply":"2025-09-08T09:16:50.194774Z"}},"outputs":[{"name":"stdout","text":"Total number of parameters: 1,498,482,688\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/304260530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Account for weight tying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtotal_params_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_params\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTotal number of unique parameters: {total_params_normalized:,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'Llama3' object has no attribute 'token_emedding'"],"ename":"AttributeError","evalue":"'Llama3' object has no attribute 'token_emedding'","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"def model_memory_size(model, input_dtype=torch.float32):\n    total_params = 0\n    total_grads = 0\n    for param in model.parameters():\n        # Calculate total number of elements per parameter\n        param_size = param.numel()\n        total_params += param_size\n        # Check if gradients are stored for this parameter\n        if param.requires_grad:\n            total_grads += param_size\n\n    # Calculate buffer size (non-parameters that require memory)\n    total_buffers = sum(buf.numel() for buf in model.buffers())\n\n    # Size in bytes = (Number of elements) * (Size of each element in bytes)\n    # We assume parameters and gradients are stored in the same type as input dtype\n    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n\n    # Convert bytes to gigabytes\n    total_memory_gb = total_memory_bytes / (1024**3)\n\n    return total_memory_gb\n\nprint(f\"float32 (PyTorch default): {model_memory_size(model, input_dtype=torch.float32):.2f} GB\")\nprint(f\"bfloat16: {model_memory_size(model, input_dtype=torch.bfloat16):.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:17:09.934204Z","iopub.execute_input":"2025-09-08T09:17:09.934490Z","iopub.status.idle":"2025-09-08T09:17:09.942863Z","shell.execute_reply.started":"2025-09-08T09:17:09.934468Z","shell.execute_reply":"2025-09-08T09:17:09.942089Z"}},"outputs":[{"name":"stdout","text":"float32 (PyTorch default): 11.42 GB\nbfloat16: 5.71 GB\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Importing necessary libraries\nimport os\nfrom pathlib import Path\n\nimport tiktoken\nfrom tiktoken.load import load_tiktoken_bpe\n\n\nclass Tokenizer:\n    def __init__(self, model_path):\n        # Ensure that the provided model path is a valid file\n        assert os.path.isfile(model_path), f\"Model file {model_path} not found\"\n        \n        # Load the mergeable ranks (Byte Pair Encoding) specific to the model\n        mergeable_ranks = load_tiktoken_bpe(model_path)\n\n        # Define special tokens for LLaMA3\n        # These tokens help manage text boundaries, reserved spaces, and other control features in the text generation process\n        self.special_tokens = {\n            \"<|begin_of_text|>\": 128000,  # Token to signify the beginning of the text\n            \"<|end_of_text|>\": 128001,    # Token to signify the end of the text\n            \"<|start_header_id|>\": 128006,  # Token for starting a header section\n            \"<|end_header_id|>\": 128007,   # Token for ending a header section\n            \"<|eot_id|>\": 128009,         # Token for end-of-text (e.g., indicating the end of a content block)\n        }\n        \n        # Additional reserved tokens for model-specific functionality (e.g., controlling certain operations)\n        self.special_tokens.update({\n            f\"<|reserved_{i}|>\": 128002 + i for i in range(256) if (128002 + i) not in self.special_tokens.values()\n        })\n\n        # Define the tokenization pattern\n        # This regular expression is more complex compared to GPT-2 and captures more varied tokenization patterns\n        # Handles contractions, special characters, and complex text formats like headers or sequences\n        self.model = tiktoken.Encoding(\n            name=Path(model_path).name,  # Use the name of the model file as the encoding name\n            pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",  # Regex pattern for tokenization\n            mergeable_ranks=mergeable_ranks,  # Load the BPE mergeable ranks specific to the model\n            special_tokens=self.special_tokens  # Include special tokens defined earlier\n        )\n\n\n    def encode(self, text, bos=False, eos=False, allowed_special=set(), disallowed_special=()):\n        \"\"\"\n        Encodes a given text input into tokens, optionally including special tokens like bos (beginning of sequence)\n        and eos (end of sequence). The `allowed_special` and `disallowed_special` parameters allow for fine control \n        over which special tokens are included.\n        \"\"\"\n        \n        tokens = []\n\n        # Optionally add the <|begin_of_text|> token if 'bos' is True (indicating the start of the sequence)\n        if bos:\n            tokens = [self.special_tokens[\"<|begin_of_text|>\"]]\n\n        # Use the tokenizer's `encode` method to tokenize the input text\n        tokens += self.model.encode(text, allowed_special=allowed_special, disallowed_special=disallowed_special)\n\n        # Optionally add the <|end_of_text|> token if 'eos' is True (indicating the end of the sequence)\n        if eos:\n            tokens.append(self.special_tokens[\"<|end_of_text|>\"])\n\n        return tokens\n\n    def decode(self, tokens):\n        \"\"\"\n        Decodes a sequence of tokens back into the original text.\n        \"\"\"\n        return self.model.decode(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:21:13.212551Z","iopub.execute_input":"2025-09-08T09:21:13.213118Z","iopub.status.idle":"2025-09-08T09:21:13.223768Z","shell.execute_reply.started":"2025-09-08T09:21:13.213094Z","shell.execute_reply":"2025-09-08T09:21:13.223165Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Make sure you have an account to generate access token \n# make sure t have the right premission to access the repo from huggingface\nfrom huggingface_hub import login\n\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:28:09.751807Z","iopub.execute_input":"2025-09-08T09:28:09.752749Z","iopub.status.idle":"2025-09-08T09:28:09.770974Z","shell.execute_reply.started":"2025-09-08T09:28:09.752713Z","shell.execute_reply":"2025-09-08T09:28:09.770090Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c491aa9d69764aaeac7f258181319f59"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"!git config --global credential.helper store\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:26:38.483218Z","iopub.execute_input":"2025-09-08T09:26:38.483494Z","iopub.status.idle":"2025-09-08T09:26:38.714386Z","shell.execute_reply.started":"2025-09-08T09:26:38.483473Z","shell.execute_reply":"2025-09-08T09:26:38.713471Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"!git lfs install\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:26:49.322551Z","iopub.execute_input":"2025-09-08T09:26:49.322851Z","iopub.status.idle":"2025-09-08T09:26:49.668258Z","shell.execute_reply.started":"2025-09-08T09:26:49.322826Z","shell.execute_reply":"2025-09-08T09:26:49.667453Z"}},"outputs":[{"name":"stdout","text":"Git LFS initialized.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nLLAMA_SIZE_STR = \"1B\" if LLAMA32_CONFIG[\"emb_dim\"] == 2048 else \"3B\"\n\n\ntokenizer_file_path = hf_hub_download(\n    repo_id=f\"meta-llama/Llama-3.2-{LLAMA_SIZE_STR}-Instruct\",\n    filename=\"original/tokenizer.model\",\n    local_dir=f\"Llama-3.2-{LLAMA_SIZE_STR}-Instruct\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T09:28:21.911557Z","iopub.execute_input":"2025-09-08T09:28:21.911834Z","iopub.status.idle":"2025-09-08T09:28:22.146796Z","shell.execute_reply.started":"2025-09-08T09:28:21.911816Z","shell.execute_reply":"2025-09-08T09:28:22.145726Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/original/tokenizer.model","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2855555300.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m tokenizer_file_path = hf_hub_download(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"meta-llama/Llama-3.2-{LLAMA_SIZE_STR}-Instruct\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"original/tokenizer.model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    986\u001b[0m             )\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         return _hf_hub_download_to_local_dir(\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_local_dir\u001b[0;34m(local_dir, repo_id, repo_type, filename, revision, endpoint, etag_timeout, headers, proxies, token, cache_dir, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;31m# Otherwise => raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;31m# From now on, etag, commit_hash, url and size are not None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1534\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0;34mf\"{response.status_code} Client Error.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Cannot access gated repo for url {response.url}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             )\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_message\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Access to this resource is disabled.\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-68bea1b6-759d7b2b4c9ac795365d9200;09abeb9d-79bb-4946-991a-084f46b944ed)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/original/tokenizer.model.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access."],"ename":"GatedRepoError","evalue":"403 Client Error. (Request ID: Root=1-68bea1b6-759d7b2b4c9ac795365d9200;09abeb9d-79bb-4946-991a-084f46b944ed)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/original/tokenizer.model.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}