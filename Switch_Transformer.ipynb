{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MoE\n",
        "Summary of Mixture of Expert models:\n",
        "\n",
        "Are pretrained much faster vs. dense models\n",
        "Have faster inference compared to a model with the same number of parameters\n",
        "Require high VRAM as all experts are loaded in memory\n",
        "Face many challenges in fine-tuning\n",
        "In the context of transformer models, a MoE consists of two main elements:\n",
        "\n",
        "Sparse MoE layers are used instead of dense feed-forward network (FFN) layers. MoE layers have a certain number of “experts” (e.g. 8), where each expert is a neural network. In practice, the experts are FFNs, but they can also be more complex networks or even a MoE itself, leading to hierarchical MoEs!\n",
        "\n",
        "A gate network or router, that determines which tokens are sent to which expert. For example, in the image below, the token “More” is sent to the second expert, and the token \"Parameters” is sent to the first network. As we’ll explore later, we can send a token to more than one expert. How to route a token to an expert is one of the big decisions when working with MoEs - the router is composed of learned parameters and is pretrained at the same time as the rest of the network."
      ],
      "metadata": {
        "id": "ri0CyuKl51e5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8q1mUM_k5qI6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "SEQ_LEN = 200\n",
        "EMBED_DIM = 128\n",
        "N_HEADS = 8\n",
        "N_EXPERT_FFNS = 6"
      ],
      "metadata": {
        "id": "9nKKDf5C6OFx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n"
      ],
      "metadata": {
        "id": "URUeT1796P-K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Switch Transformer\n",
        "\n",
        "class MySwitchTransformer(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, seq_len, nheads, n_experts):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.positional_encodings = nn.Embedding(seq_len, embed_dim)\n",
        "    self.positional_inputs = torch.from_numpy(np.arange(seq_len))\n",
        "    self.multi_head_self_attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=nheads, batch_first=True)\n",
        "    self.layer_norm_1 = nn.LayerNorm((embed_dim))\n",
        "    # Router needs to select one of the k experts we have. Each token can go to a different expert FFN.\n",
        "    self.router = nn.Linear(embed_dim, n_experts)\n",
        "    # The list of Expert FFNs.\n",
        "    # Note that wrapping this python list inside of `nn.ModuleList` is crucial\n",
        "    # otherwise these FFN parameters don't show up in model.parameters() - which\n",
        "    # means that backprop won't update those weights.\n",
        "    self.expert_ffns = nn.ModuleList([\n",
        "        nn.Sequential(\n",
        "          OrderedDict([\n",
        "          (f'%d-ffn-l1'.format(i), nn.Linear(embed_dim, 2048)),\n",
        "          (f'%d-ffn-l2'.format(i), nn.Linear(2048, embed_dim))]))\n",
        "        for i in range(n_experts)])\n",
        "    self.layer_norm_2 = nn.LayerNorm((embed_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding_layer(x)\n",
        "    x = x + self.positional_encodings(self.positional_inputs)\n",
        "    print(\"x.shape: \", x.shape)\n",
        "    old_x = x\n",
        "    x, _ = self.multi_head_self_attention(query=x, key=x, value=x)\n",
        "    x = self.layer_norm_1(x + old_x)\n",
        "    print(\"x.shape: \", x.shape)\n",
        "    h = self.router(x)\n",
        "    print(\"h.shape: \", h.shape)\n",
        "    # Take argmax of this to decide the index of which expert to use.\n",
        "    ffn_layer_idx = torch.argmax(h, dim=-1)\n",
        "    print(\"\\nffn_layer_idx.shape: \", ffn_layer_idx.shape)\n",
        "\n",
        "    # Initialize result of MOE to zeros. Then populate batchwise & tokenwise.\n",
        "    result_of_moe = torch.zeros(x.shape)\n",
        "    for batch_idx in range(x.shape[0]):\n",
        "      for token_idx in range(x.shape[1]):\n",
        "        selected_ffn_layer = self.expert_ffns[ffn_layer_idx[batch_idx][token_idx]]\n",
        "        result_of_moe[batch_idx][token_idx] = selected_ffn_layer(x[batch_idx][token_idx])\n",
        "\n",
        "    print(\"result_of_moe.shape: \", result_of_moe.shape)\n",
        "    # Final Add & Norm\n",
        "    x = self.layer_norm_2(x + result_of_moe)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NPIQ-Fe56Wv9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randint(VOCAB_SIZE, (5, SEQ_LEN))\n",
        "mst = MySwitchTransformer(VOCAB_SIZE, EMBED_DIM, SEQ_LEN, N_HEADS, N_EXPERT_FFNS)\n",
        "mst(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvmDxZ246abv",
        "outputId": "5c848ca5-7d8d-4a29-9ab6-2c7a40f8bec3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape:  torch.Size([5, 200, 128])\n",
            "x.shape:  torch.Size([5, 200, 128])\n",
            "h.shape:  torch.Size([5, 200, 6])\n",
            "\n",
            "ffn_layer_idx.shape:  torch.Size([5, 200])\n",
            "result_of_moe.shape:  torch.Size([5, 200, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 200, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([3, 5, 9, -1, 0])\n",
        "torch.argmax(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_jTh2ys6jBg",
        "outputId": "9b7015ff-cccd-4cd7-f012-c5007fb56add"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[[3, 5, 9, -1, 0], [3, 5, 9, -1, 10]]])\n",
        "torch.argmax(t, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHBsgJfu6kuZ",
        "outputId": "5075f857-5aed-46c4-89bd-5ab4fc4a599b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mst.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJZZI2eQ6mbZ",
        "outputId": "ef068cd1-c9a2-46f2-dd42-ce327304b007"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7bb00bcc0ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at number of parameters\n",
        "\n",
        "for p in mst.parameters():\n",
        "  print(p.name, p.shape, p.numel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVYqS1JU6oaF",
        "outputId": "30c6183e-0a08-4a6c-c436-d6819b07e629"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None torch.Size([1000, 128]) 128000\n",
            "None torch.Size([200, 128]) 25600\n",
            "None torch.Size([384, 128]) 49152\n",
            "None torch.Size([384]) 384\n",
            "None torch.Size([128, 128]) 16384\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([6, 128]) 768\n",
            "None torch.Size([6]) 6\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([2048, 128]) 262144\n",
            "None torch.Size([2048]) 2048\n",
            "None torch.Size([128, 2048]) 262144\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([128]) 128\n",
            "None torch.Size([128]) 128\n"
          ]
        }
      ]
    }
  ]
}